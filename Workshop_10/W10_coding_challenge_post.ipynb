{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc0ec06",
   "metadata": {},
   "source": [
    "# `AA Workshop 10` â€” Coding Challenge\n",
    "\n",
    "Complete the tasks below to practice implementing classification modeling from `W10_Neural_Networks.ipynb`.\n",
    "\n",
    "Guidelines:\n",
    "- Work in order. Run each cell after editing with Shift+Enter.\n",
    "- Keep answers short; focus on making things work.\n",
    "- If a step fails, read the error and fix it.\n",
    "\n",
    "By the end you will have exercised:\n",
    "- defining an architecture of a NN\n",
    "- implementing a NN for a multi-class classification problem\n",
    "- evaluating performance throughout the fitting process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fdc70a",
   "metadata": {},
   "source": [
    "## Task 1 - Employing a Neural Network to Classify Breast Cancer Cells\n",
    "\n",
    "In the workshop notebook, you learned how to use the keras framework for both classifcation and regression prediction. The classification example we used was for a binary output (cancer cells being benign or malignant). Let's see how we can employ neural networks for multi-class classification. Do the following:\n",
    "\n",
    "1. Use the `../data/iris.csv` dataset and preproccess it as usual.\n",
    "2. Think of an architecture you would employ to enable multi-class classification. You can get some inspiration [here](https://keras.io/guides/sequential_model/).\n",
    "3. Implement a pipeline that consists of the following:\n",
    "    1. train the model on training data\n",
    "    2. evaluate and visualize loss on a training and validation set throughout the fitting of the network\n",
    "4. Use that pipeline to test different architectures / hyperparameters\n",
    "5. Report final performance on the test set\n",
    "6. Think about the model complexity vs. performance tradeoff - is the NN the best overall model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d985a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "iris = pd.read_csv('../data/iris.csv')\n",
    "iris.dropna(inplace=True)\n",
    "\n",
    "X = iris[['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']]\n",
    "y = iris['Species']\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical target vector\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5130a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NN model using Keras Sequential API\n",
    "## initialize\n",
    "model = Sequential()\n",
    "\n",
    "## add input layer\n",
    "model.add(Input((4,)))\n",
    "\n",
    "## add first hidden layer\n",
    "model.add(Dense(64, activation=None)) # linear combination\n",
    "# model.add(Dropout(rate = 0.1)) # optional: dropout\n",
    "\n",
    "## add second hidden layer\n",
    "model.add(Dense(32, activation='relu')) # Rectified Linear Unit activation function\n",
    "# model.add(Dropout(rate = 0.1)) # optional: dropout\n",
    "\n",
    "## add output layer with one node per output class (i.e. for each iris species)\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "## compile\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3daa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate\n",
    "def train_and_evaluate(model, visualize=False):\n",
    "    history = model.fit(X_train, y_train, batch_size = 20, epochs = 20, validation_split=0.3)\n",
    "    if visualize:\n",
    "        pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b95e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute\n",
    "train_and_evaluate(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance on test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd36f1",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Remember that the dataset is (before filtering out NaN) just 50 records of every class (species), so it is a really small dataset and there is really no reason to opt for a neural network here! Indeed, these results can be easily achieved with a SVM or Logistic Regression.\n",
    "\n",
    "This is an important lesson: even though this small NN is fast to build and fit, it is\n",
    "1. inefficient to use a large network for the task\n",
    "1. unnecessary to introduce an opaque method, where we have no idea about things like feature importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
