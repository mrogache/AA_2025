{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `AA Workshop 10` - Introduction to Neural Networks\n",
    "\n",
    "In this workshop we provide a very short introduction to neural networks in Python. This is very far from a comprehensive coverage of the topic but can provide a quick start for those who wish to learn more about the topic in their own time. We will cover a classification and a regression task using `keras` as our python package of choice. If you want to try and implement a NN from scratch, there are several good online tutorials that can help you do so (see [here](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6) for example).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological inspiration\n",
    "The (for our purpose) smallest stand-alone element in the human brain is the neuron. Its understanding and computational recreation build the foundation for ANNs. A simplified image of a \"real\" neuron can be seen below:\n",
    "\n",
    "![](bio_neuron.png)\n",
    "\n",
    "Dendrites are connecting to the axons (or \"outputs\") of other neurons, for instance, nerves in the sensory system or other processing neurons. In the nucleus, these input signals are aggregated and forwarded through the axon. The axon terminals then connect to further neurons to build the neural network. The connection between axon terminal and dendrite is what we are calling a synapse. In the human brain, there are billions of neurons and $10^{14} - 10^{15}$ synapses in the human brain. If each synapse (or more precisely, its connection strength) would be represented by 8 bits or one byte, just storing these numbers would take 1000 TB already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational implementation\n",
    "To recreate neural networks artificially, neurons have to be defined. The common mathematical model used for this purpose is depicted below:\n",
    "\n",
    "![](math_neuron.jpeg)\n",
    "\n",
    "From a certain number of input synapses $x_i$, signals come in with a weight factor of $w_i$. This represents the strength of the synapse. In the _nucleus_ these weighted inputs are aggregated and a bias is added. The bias is not explicitly shown in every model, but it does make the neural network more generalizable. After adding of the weighted inputs and the bias, everything is fed into a (non-linear) activation function. The output is then either fed forward to further neurons or is the output of your neural network. If there is only one neuron that takes direct inputs and whose output is your interest, the model is called a single-layer perceptron. Many of these neurons can create almost arbitrary logical connections and functions, making ANNs very powerful. In this case, we are talking about a multi-layer perceptron (MLP) model: \n",
    "\n",
    "![](mlp-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "The activation function is (to some degree) the heart of the neural network. Without a non-linear activation function, all hidden layers do not add any value, but are instead a complicated way to represent a liner model. Only with a non-linear activation function, ANNs can recreate non-linear hypothesis functions. In the beginning of research on the ANNs in the scope of AI, typically a unit step was used as an activation function. The unit step is $0$ for inputs smaller than $0$ and $1$ otherwise. The idea behind this is to recreate the behavior of a biological neuron that _fires_ if a certain threshold of inputs is exceeded. Today, other activation functions are more commonly used. This is linked to better mathematical qualities in terms of learning behavior and convergence. Some of the most popular activation functions are:\n",
    "\n",
    "Sigmoid: $\\sigma(z) = \\frac{1}{1+exp(-z)}$\n",
    "\n",
    "Hyperbolic tangent: $\\sigma(z) = \\frac{2}{1+exp(-2z)} -1 $\n",
    "\n",
    "ReLU (Rectified Linear Unit): $\\sigma(z) = z\\quad  for\\ z>0,\\ 0\\ otherwise$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "As learning of ANNs is a non-trivial mathematical task, we are only aiming for an intuitive understanding here. Let's have a look at our complete MLP first.\n",
    "\n",
    "The general learning task consists of two steps, which are repeated until the algorithm converges:\n",
    "1. __Feedforward: Calculating the predicted output ŷ and the associated loss__. At first, we randomly assign values for the weights (and the biases). Based on the input features, the output value is calculated.\n",
    "2. __Backpropagation: Updating the weights W and biases b__. If the output value and the target value differ, the weights and biases are updated. To do this, it is calculated how much each weight and bias contributes to the error. Proportionally to this, they are then corrected (scaled with a small learning factor). In this sense, the updating rule has some similarity to gradient descent, only that is is propagated through the entire network, which is why this algorithm is called backpropagation.\n",
    "\n",
    "The training routine for a simple 2-layered MLP is shown in the below figure:\n",
    "\n",
    "![](training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "The main hyperparameters of an MLP are: \n",
    "\n",
    "1. Number of hidden layers\n",
    "1. Number of nodes\n",
    "4. Activation function\n",
    "\n",
    "The more layers and nodes there are (and the denser the network is, i.e. the more edges have a non-zero weight) the harder it gets to learn the model. That's the reason why bigger ANNs are normally not trained on a local computer anymore, but on specialized computers. Furthermore, there are additional libraries for python to improve the efficiency of ANNs, e.g. TensorFlow or Keras, which we take a first look at in today's tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras` is one of the most popular Deep Learning libraries. `PyTorch` and `Jax` are the most used numerical platforms in Python to build Deep Learning algorithms but they can be quite complex and difficult to use.\n",
    "\n",
    "Keras, by contrast, is easy to use and is capable of running on top of multiple low-level tensor operation frameworks. The full documentation of the keras API can be found [here](https://keras.io).\n",
    "\n",
    "Note that `scikit learn` also features an MLP implementation (see [here](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)). Yet, `keras` has advanced to be one of the most popular frameworks used in practice, which is why we focus on it in this short tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `Keras` to command `PyTorch`, therefore we need to install both.\n",
    "\n",
    "PyTorch's installation method varies by platform and environment manager, all of the options are listed [here](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "If you use the provided `environment.yml` specification, you should be set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks for classification in `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stay with our example, we will build a NN that predicts the class of a breast cancer cell by categorizing it as either malignant or benign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# supress versioning warnings of keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because keras can work with multiple different backends, it is important to specify that we want to use PyTorch before importing keras for the first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential # sequential model: https://keras.io/guides/sequential_model/\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                       \n",
       "842302         M        17.99         10.38           122.8     1001.0   \n",
       "842517         M        20.57         17.77           132.9     1326.0   \n",
       "\n",
       "        smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                          \n",
       "842302          0.11840           0.27760          0.3001   \n",
       "842517          0.08474           0.07864          0.0869   \n",
       "\n",
       "        concave points_mean  symmetry_mean  ...  radius_worst  texture_worst  \\\n",
       "id                                          ...                                \n",
       "842302              0.14710         0.2419  ...         25.38          17.33   \n",
       "842517              0.07017         0.1812  ...         24.99          23.41   \n",
       "\n",
       "        perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                         \n",
       "842302            184.6      2019.0            0.1622             0.6656   \n",
       "842517            158.8      1956.0            0.1238             0.1866   \n",
       "\n",
       "        concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                              \n",
       "842302           0.7119                0.2654          0.4601   \n",
       "842517           0.2416                0.1860          0.2750   \n",
       "\n",
       "        fractal_dimension_worst  \n",
       "id                               \n",
       "842302                  0.11890  \n",
       "842517                  0.08902  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "cancer_df = pd.read_csv(\"../data/breast_cancer.csv\", index_col = \"id\")\n",
    "cancer_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and Y\n",
    "X = cancer_df.iloc[:,1:31] # include full feature vector\n",
    "y = cancer_df[\"diagnosis\"]\n",
    "\n",
    "\n",
    "# encode categorical target vector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing and Training the ANN\n",
    "\n",
    "We start by defining the type of model we want to build. There are two types of models available in Keras: the [Sequential model](https://keras.io/models/sequential/) and the model class used with [functional API](https://keras.io/models/model/). Then, we simply add the input-, hidden- and output-layers.\n",
    "\n",
    "Between them, we are using [dropout](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer) to prevent overfitting (dropout rate should be between 20% and 50%).\n",
    "\n",
    "![](dropout.png)\n",
    "\n",
    "At every layer, we use “Dense” which means that the nodes are fully connected.\n",
    "\n",
    "In our example, the input-layer takes 30 inputs (because our feature vector includes 30 features) and outputs it with a shape of 15, which is the number of nodes in the first hidden layer that we define. Then, we define a second hidden layer with 15 nodes, before adding the output layer with a single node (since we are solving a binary classification problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pass the following parameters:\n",
    "\n",
    "- input_shape - number of columns of the dataset (only for input layer)\n",
    "\n",
    "- units - number of neurons and dimensionality of outputs to be fed to the next layer, if any\n",
    "\n",
    "- activation - activation function (we use ReLU in this case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the input layer and the first hidden layer (with 15 nodes)\n",
    "classifier.add(Dense(input_shape = (30,), \n",
    "                     units=15,          # dimensionality of the output space (# of nodes in the first hidden layer)\n",
    "                     activation='relu'))\n",
    "\n",
    "# adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an additional second layer, also with 15 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the second hidden layer\n",
    "classifier.add(Dense(units= 15,\n",
    "                     activation='relu'))\n",
    "\n",
    "# adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the output layer. Since we perform a binary classification, a single output node suffices. We use a sigmoidal activation function for this last node which is often used when dealing with binary classfication problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the output layer\n",
    "classifier.add(Dense(units= 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compile the model to configure it for training. We add the following parameters:\n",
    "- `optimizer`: Here we use the adam optimizer, an optimizer with higher performance in many cases than stochastic gradient descent (SGD). See [here](https://keras.io/optimizers/) for a list of all optimizers implemented in `keras`.\n",
    "- `loss`: specifies the loss to be minimized. In this example we use binary cross-entropy, a common loss for binary classification tasks. See [here](https://keras.io/losses/) for an overview of available losses in `keras`.\n",
    "- `metrics`: the metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model and merely function as an indicator of model performance to the data scientist. In this example we report the accuracy. An overview ov available metrics can be found [here](https://keras.io/metrics/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the ANN\n",
    "classifier.compile(optimizer=\"adam\",    # Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments\n",
    "              loss=\"binary_crossentropy\",  # this is a good loss for binary classification\n",
    "              metrics=[\"accuracy\"]) # standard classification evaluation emtric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m465\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m16\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">721</span> (2.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m721\u001b[0m (2.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">721</span> (2.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m721\u001b[0m (2.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to train our model. We do this with a batch_size of 50 and for 100 epochs.\n",
    "\n",
    "- `batch_size` defines the number of samples that will be propagated through the network \n",
    "- `epoch` defines the number of iterations over the entire training data\n",
    "\n",
    "In general a larger batch-size results in faster training, but does not always converge fast. A smaller batch-size is slower in training but it can converge faster. This is definitely problem-dependent and you need to try out a few different values (the standard batch-size is 32). The same goes for the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7312 - loss: 0.5890\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7965 - loss: 0.5513\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8216 - loss: 0.5113\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8543 - loss: 0.4627\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8945 - loss: 0.4137\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9221 - loss: 0.3679\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9070 - loss: 0.3599\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9070 - loss: 0.3239\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9322 - loss: 0.2896\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9296 - loss: 0.2620\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9347 - loss: 0.2389\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9623 - loss: 0.2195\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9548 - loss: 0.1978\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9548 - loss: 0.2004\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9472 - loss: 0.1879\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9623 - loss: 0.1848\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9472 - loss: 0.1730\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9598 - loss: 0.1597\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9598 - loss: 0.1566\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9623 - loss: 0.1386\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9648 - loss: 0.1337\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9749 - loss: 0.1292\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9573 - loss: 0.1406\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9673 - loss: 0.1115\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9774 - loss: 0.1069\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9698 - loss: 0.0994\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9548 - loss: 0.1211\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9673 - loss: 0.1091\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9724 - loss: 0.1066\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9648 - loss: 0.1224\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9673 - loss: 0.1089\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9724 - loss: 0.0956\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9749 - loss: 0.1010\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9724 - loss: 0.0917\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9724 - loss: 0.1065\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9698 - loss: 0.0983\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9648 - loss: 0.1040\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9849 - loss: 0.0843\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0883\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9774 - loss: 0.0823\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9774 - loss: 0.0756\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9698 - loss: 0.0947\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9749 - loss: 0.0780\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9774 - loss: 0.0739\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9749 - loss: 0.0815\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9849 - loss: 0.0631\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9749 - loss: 0.0822\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9824 - loss: 0.0839\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9749 - loss: 0.0676\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9799 - loss: 0.0660\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0722\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9749 - loss: 0.0754\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0613\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9799 - loss: 0.0776\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0805\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9749 - loss: 0.0643\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9774 - loss: 0.0703\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9749 - loss: 0.0667 \n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9849 - loss: 0.0541\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0747\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0658\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9824 - loss: 0.0590\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9874 - loss: 0.0517\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9874 - loss: 0.0552\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9824 - loss: 0.0539\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9799 - loss: 0.0591\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9774 - loss: 0.0644\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0689\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9849 - loss: 0.0581\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9799 - loss: 0.0547\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.0572 \n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0574\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.0610\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9849 - loss: 0.0502\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9824 - loss: 0.0497\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9774 - loss: 0.0580\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.0505\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0428\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9799 - loss: 0.0565\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0541\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9874 - loss: 0.0637\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9925 - loss: 0.0473\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0435\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9874 - loss: 0.0487\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9824 - loss: 0.0505\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9824 - loss: 0.0498\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0436\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.0571\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0552\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0393\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9849 - loss: 0.0400\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9849 - loss: 0.0436\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0432\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0440\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9874 - loss: 0.0374\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0430\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9799 - loss: 0.0594\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9874 - loss: 0.0391\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9849 - loss: 0.0454\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9824 - loss: 0.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22a6008ba60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Confusion Matrix\n",
      "[[107   1]\n",
      " [  1  62]]\n",
      "\n",
      "Accuracy\n",
      "0.9883\n",
      "\n",
      "Precision\n",
      "0.9841\n"
     ]
    }
   ],
   "source": [
    "# report classification performance on test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "accuracy_score = accuracy_score(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "precision_score = precision_score(y_test, classifier.predict(X_test).round(decimals=0).astype(int))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "print(\"Accuracy\")\n",
    "print(round(accuracy_score, ndigits=4))\n",
    "print()\n",
    "print(\"Precision\")\n",
    "print(round(precision_score, ndigits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks for regression in `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can also be trained for regression tasks. The logic is exactly the same, yet some of the parameters, such as loss, metrics, input and ouput as well as typical activation functions might have to be adapted to the specific case. There are a range of very good tutorials online, which we encourage you to take a look at (for example [here](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)). \n",
    "\n",
    "We will cover a simple implimentation on the `Diamonds` dataset. The objective in this task is to predict the price of a particular diamond based on different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25412</th>\n",
       "      <td>2.14</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>SI2</td>\n",
       "      <td>60.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>14138</td>\n",
       "      <td>8.34</td>\n",
       "      <td>8.40</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31267</th>\n",
       "      <td>0.32</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>449</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19481</th>\n",
       "      <td>1.67</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8118</td>\n",
       "      <td>7.57</td>\n",
       "      <td>7.52</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35203</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>VS1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>891</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.83</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39720</th>\n",
       "      <td>0.54</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1090</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "25412   2.14      Ideal     I     SI2   60.7   57.0  14138  8.34  8.40  5.08\n",
       "31267   0.32      Ideal     I     VS2   62.5   55.0    449  4.37  4.40  2.74\n",
       "19481   1.67    Premium     H     SI2   62.6   60.0   8118  7.57  7.52  4.72\n",
       "35203   0.44  Very Good     J     VS1   63.1   57.0    891  4.87  4.83  3.06\n",
       "39720   0.54    Premium     G     SI2   61.4   59.0   1090  5.21  5.24  3.21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table         price             x  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
       "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
       "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
       "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
       "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
       "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
       "\n",
       "                  y             z  \n",
       "count  53940.000000  53940.000000  \n",
       "mean       5.734526      3.538734  \n",
       "std        1.142135      0.705699  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.530000  \n",
       "75%        6.540000      4.040000  \n",
       "max       58.900000     31.800000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data\n",
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAHPCAYAAAD9FLv9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMI9JREFUeJzt3XmczXX///HnOWY1g2EGX2SMLRRjLBXjUpMl+UpSXVku+/RtQRuVFAa5MtnC19VqCZV8uUJR2amUfSlxUcaaJUv2ZcbM+/eHn3M5zXDGFZ/PvPO4327ndjPv8znnvM7BvM7r9X5/3h+PMcYIAAA4wut2AAAA3EhIvAAAOIjECwCAg0i8AAA4iMQLAICDSLwAADiIxAsAgINIvAAAOIjECwCAg0i8N5gVK1aoZcuWio2NVWhoqIoXL666deuqZ8+efsfFxcXpvvvucynKK1uyZIk8Ho88Ho/ef//9HI9p0KCBPB6P4uLi/Mbj4uLUqVOnax5Tp06dsr3W9ZaRkaHixYurTp06lz0mKytLsbGxio+Pz/XzXvx8lyxZcg2iBPB7JN4byJw5c5SYmKjjx49ryJAhmjdvnkaNGqV69epp6tSpbod31QoUKKBx48ZlG9++fbuWLFmiggULZrtvxowZ6tu37zWPpW/fvpoxY8Y1f94rCQ4OVvv27bVixQpt2rQpx2MWLFig3bt3Kzk52dHYAFweifcGMmTIEJUtW1Zz585V69atddddd6l169YaNmyYdu3a5XZ4V61Vq1b65ptv9NNPP/mNjx8/XqVKlVK9evWyPaZGjRoqX778NY+lfPnyqlGjxjV/3kAuJtTx48fneP/48eMVEhKidu3aORkWgCsg8d5ADh8+rJiYGAUFBWW7z+vN+Z/Cl19+qZo1ayo8PFyVK1fO8Rf8xo0b1aJFCxUuXFhhYWFKSEjQxIkTffcbY1S8eHF169bNN5aZmanChQvL6/XqwIEDvvERI0YoKChIR48eDfh+GjdurNKlS/vFlJWVpYkTJ6pjx445vqfft5qzsrI0aNAgVapUSeHh4YqKilJ8fLxGjRrlO+bgwYN67LHHVLp0aYWGhqpo0aKqV6+eFixY4Dsmp1azx+NR9+7dNXnyZFWpUkX58+dX9erVNXv27GxxzZo1S/Hx8QoNDVW5cuU0atQo9e/fXx6P54qfQZUqVVS3bl1NnjxZ58+f97vv6NGjmjVrllq0aKHo6GitXr1arVu3VlxcnMLDwxUXF6c2bdpo586dV3wNSUpKSlJSUlK28Zzed3p6ugYNGqTKlSv7Pq/OnTvr4MGDfsctWrRISUlJio6OVnh4uGJjY/XQQw/p9OnTAeMBbEbivYHUrVtXK1as0NNPP60VK1YoIyPjisdv2LBBPXv21HPPPedLDMnJyfrqq698x2zZskWJiYn68ccfNXr0aH3yySe65ZZb1KlTJw0ZMkTShQTUoEEDv0S1evVqHT16VGFhYVq4cKFvfMGCBapVq5aioqICvh+v16tOnTpp0qRJyszMlCTNmzdPe/bsUefOnXP1mQwZMkT9+/dXmzZtNGfOHE2dOlXJycl+ib99+/aaOXOm+vXrp3nz5mns2LFq1KiRDh8+HPD558yZozFjxmjgwIH65z//qSJFiqhly5ZKS0vzHfPll1/qwQcfVHR0tKZOnaohQ4ZoypQpfl9eriQ5OVm//vqr5syZ4zf+0Ucf6ezZs76qeMeOHapUqZJGjhypuXPn6vXXX9e+fft022236dChQ7l6rUCysrLUokULpaamqm3btpozZ45SU1M1f/58JSUl6cyZM75YmjVrppCQEI0fP15ffvmlUlNTFRERofT09GsSC5BnGdwwDh06ZP7yl78YSUaSCQ4ONomJiWbw4MHmxIkTfseWKVPGhIWFmZ07d/rGzpw5Y4oUKWIef/xx31jr1q1NaGio2bVrl9/jmzZtavLnz2+OHj1qjDFm7NixRpLvuEGDBpnKlSub+++/33Tu3NkYY0x6erqJiIgwL7/88hXfx+LFi40kM23aNJOWlmY8Ho+ZPXu2McaYv/71ryYpKckYY0yzZs1MmTJlsr2vjh07+n6+7777TEJCwhVfLzIy0jz77LNXPKZjx47ZXkuSKV68uDl+/LhvbP/+/cbr9ZrBgwf7xm677TZTunRpc+7cOd/YiRMnTHR0tMnNf9ETJ06YyMhIc//99/uN16pVy5QuXdpkZmbm+Ljz58+bkydPmoiICDNq1Cjf+MXPd/Hixb6xu+66y9x1110B3/eUKVOMJPPPf/7T77hVq1YZSebNN980xhgzffp0I8msX78+4PsD/myoeG8g0dHR+vrrr7Vq1SqlpqaqRYsW2rp1q3r37q1q1aplq3oSEhIUGxvr+zksLEw333yzX2ty0aJFatiwoUqXLu332E6dOun06dP67rvvJEmNGjWSJF/VO3/+fDVu3FiNGjXS/PnzJUnfffedTp065Ts2N8qWLaukpCSNHz9ehw8f1qxZs9SlS5dcP/7222/Xhg0b1LVrV82dO1fHjx/P8Zj3339fgwYN0vLlywN2Ci519913q0CBAr6fixcvrmLFivk+w1OnTmn16tV64IEHFBIS4jsuMjJSzZs3z9VrREZG6pFHHtHnn3/ua9tv3LhRa9asUadOnXwt95MnT6pXr16qUKGCgoKCFBQUpMjISJ06dUqbN2/O9Xu6ktmzZysqKkrNmzfX+fPnfbeEhAT913/9l2+ldEJCgkJCQvTYY49p4sSJfh0A4M+OxHsDql27tnr16qVp06Zp7969eu6557Rjxw5fa/ii6OjobI8NDQ31tQulC/PGJUqUyHZcyZIlffdLUpkyZVS+fHktWLDAl5AvJt49e/Zoy5YtWrBggcLDw5WYmHhV7yc5OVmfffaZRowYofDwcD388MO5fmzv3r01bNgwLV++XE2bNlV0dLQaNmyo1atX+46ZOnWqOnbsqLFjx6pu3boqUqSIOnTooP379wd8/kCf4W+//eabA/+9nMYuJzk5WefPn9fkyZMlXVhU5fF4/Frubdu21ZgxY/Too49q7ty5WrlypVatWqWiRYv6/Z3+EQcOHNDRo0cVEhKi4OBgv9v+/ft9X+4u/lsoVqyYunXrpvLly6t8+fJ+c+vAnxWJ9wYXHByslJQUSReqpKsVHR2tffv2ZRvfu3evJCkmJsY31rBhQy1cuFBLly5VVlaWkpKSVKVKFZUsWVLz58/XggULVL9+fYWGhl5VDA8++KDy58+v1NRUtW7dWuHh4bl+bFBQkHr06KG1a9fqyJEjmjJlinbv3q0mTZr4FvnExMRo5MiR2rFjh3bu3KnBgwfrk08+uSbnAxcuXFgej8dvgdlFuUnsFyUmJqpKlSqaMGGCMjIy9MEHH6hBgwYqW7asJOnYsWOaPXu2XnzxRb300ktq2LChbrvtNlWrVk1HjhwJ+PxhYWE6d+5ctvHfd0liYmIUHR2tVatW5Xh78803fcfWr19fn332mY4dO6bly5erbt26evbZZ/Xxxx/n+n0DNiLx3kBySpCSfG3Gi1Xq1WjYsKEWLVrkS7QXTZo0Sfnz5/fb3KFRo0Y6cOCARo4cqTp16vhasA0bNtSMGTO0atWqq2ozXxQeHq5+/fqpefPmevLJJ6/68RdFRUXp4YcfVrdu3XTkyBHt2LEj2zGxsbHq3r27GjdurLVr1/7Hr3VRRESEateurZkzZ/otKjp58mSOq5+vpEuXLtq0aZP69OmjgwcP+rXcPR6PjDHZvtSMHTvWtzDtSuLi4rR161a/5Hv48GF9++23fsfdd999Onz4sDIzM1W7du1st0qVKmV77nz58umOO+7QP/7xD0m6Jp8rkJdlP68Ef1pNmjTRTTfdpObNm6ty5crKysrS+vXrNXz4cEVGRuqZZ5656udMSUnR7Nmzdffdd6tfv34qUqSIPvzwQ82ZM0dDhgxRoUKFfMde3E1q3rx5GjBggG+8UaNG6tixo+/P/4kePXqoR48eV/245s2bq2rVqqpdu7aKFi2qnTt3auTIkSpTpowqVqyoY8eO6e6771bbtm1VuXJlFShQQKtWrfKtRL4WBg4cqGbNmqlJkyZ65plnlJmZqaFDhyoyMjJX1ehFHTp00Msvv6yhQ4cqKirKL76CBQvqzjvv1NChQxUTE6O4uDgtXbpU48aNy9UK8vbt2+udd95Ru3bt9D//8z86fPiwhgwZkm2TktatW+vDDz/Uf//3f+uZZ57R7bffruDgYO3Zs0eLFy9WixYt1LJlS7399ttatGiRmjVrptjYWJ09e9Z3Wth/+m8AsIbbq7vgnKlTp5q2bduaihUrmsjISBMcHGxiY2NN+/btzaZNm/yOLVOmjGnWrFm258hpdesPP/xgmjdvbgoVKmRCQkJM9erVzYQJE3KMoUaNGkaSWbZsmW/sl19+MZJMdHS0ycrKCvg+Ll3VfCW5WdU8fPhwk5iYaGJiYkxISIiJjY01ycnJZseOHcYYY86ePWueeOIJEx8fbwoWLGjCw8NNpUqVTEpKijl16pTveS63qrlbt27Z4vp9DMYYM2PGDFOtWjVfDKmpqebpp582hQsXDvh5XKply5ZGkunatWu2+/bs2WMeeughU7hwYVOgQAFz7733mo0bN2aLJ6dVzcYYM3HiRFOlShUTFhZmbrnlFjN16tQc33dGRoYZNmyYqV69ugkLCzORkZGmcuXK5vHHHzc//fSTMcaY7777zrRs2dKUKVPGhIaGmujoaHPXXXeZTz/99KreL2AjjzHGuJn4AWSXkZGhhIQElSpVSvPmzXM7HADXEK1mIA9ITk5W48aNVaJECe3fv19vv/22Nm/ezCpf4E+IxAvkASdOnNDzzz+vgwcPKjg4WDVr1tTnn3/OfCfwJ0SrGQAAB3E6EQAAufTVV1+pefPmKlmypDwej2bOnHnVz0HiBQAgl06dOqXq1atrzJgx//FzMMcLAEAuNW3aVE2bNv1Dz0HiBQDc0M6dO5dtS9TQ0NCr3r42t3KfeE8fuy4BAAD+hPIXCnzMH/SEp2Dgg3Lhv1J6+O2mJ13Yla9///7X5Pl/j4oXAHBD6927d7YtZ69XtSuReAEAlrpWq4OvZ1s5JyReAICVvB6P2yH8R0i8AADk0smTJ/Xzzz/7ft6+fbvWr1+vIkWKKDY2NlfPkfudq1hcBQDILQcWVz3tvTavMTor9/ltyZIluvvuu7ONd+zYUe+//36unoOKFwBgJa8LneakpCT90Z2WSbwAACvZuvWirXEDAGAlKl4AgJVY1QwAgINsbdnaGjcAAFai4gUAWMmNVc3XAokXAGAlW1u2tsYNAICVqHgBAFbysKoZAADn2NqytTVuAACsRMULALASq5oBAHCQrS1bEi8AwEq2bhlp6xcGAACsRMULALCSrZUjiRcAYCVbF1fZ+oUBAAArUfECAKxka+VI4gUAWMkrO3vNtn5hAADASlS8AAAr2bq4isQLALCSrS1bEi8AwEq2Vry2fmEAAMBKVLwAACvZuqqZxAsAsBKtZgAAEBAVLwDASrZWjiReAICVaDUDAICAqHgBAFZiVTMAAA6i1QwAAAKi4gUAWMnSgpfECwCwk62tZhIvAMBKti6uYo4XAAAHUfECAKxEqxkAAAfZ2rK1NW4AAKxExQsAsJKlnWYSLwDATl6PnamXVjMAAA6i4gUAWMnOepfECwCwlK2Jl1YzAAAOouIFAFjJ1oqXxAsAsJLH0lXNJF4AgJXsTLvM8QIA4CgqXgCAlWytHEm8AAArWTrFa+0XBgAArETFCwCwksfS5VUkXgCAlexMu7SaAQBwFBUvAMBKtla8JF4AgJW8lmZeWs0AADiIihcAYCVWNQMA4CA70y6JFwBgKXauAgAAAVHxAgCsZGnBS+IFANjJa2nqpdUMAICDqHgBAFays94l8QIALMWqZgAAEBAVLwDASpYWvCReAICdbN0yklYzAAAOouIFAFjJ1ssCkngBAFayNO+SeAEAdrI18TLHCwCAg6h4AQBWsnVVM4kXAGAldq4CAAABUfECAKxka+VI4gUAWMnSTrO1XxgAALASFS8AwEoeS1dXkXgBAFayM+3SagYAwFFUvAAAK9la8ZJ4AQBWYo4XAAAH2XpZQOZ4AQBwEBUvAMBKHktLXhIvAMBKlk7x0moGAMBJVLwAACvZWvGSeAEAVrL1dCJazQAAOIiKFwBgJUsLXhIvAMBOtJoBAEBAVLwAACtZWvCSeAEAdvJamnlJvAAAK1mad5njBQDASVS8AAAr2bqqmcQLALCSx9KeraVhAwBgJypeAICVaDUDAOAgS/MurWYAAJxExQsAsBKtZgAAHGRp3qXVDACAk6h4AQBWYq9mAAAcZGneJfECAOxk6+Iq5ngBAHAQFS8AwEqWFrwkXgCAnWxNvLSaAQBwEBUvAMBKHq+dJS+JFwBgJVrNAAAgICpeAICV2LkKAAAHWZp3aTUDAOAkKl4AgJVs3TKSxAsAsJKleZfECwCwk60VL3O8AAA4iIoXAGAlSwteEi8AwE60mgEAQEBUvAAAK3ksLR1JvAAAK9FqBgAAAVHxAgDsxPV4AQBwEK1mAAAQCBUvAMBKti6uIvECAOzEHC8AAA6ytOJljhcAAAdR8QIArOSh1QwAgINoNQMAgECoeAEAVqLVDACAk2g1AwCAQKh4AQB2otUMAIBzbN0yklYzAAAOouIFANiJVjMAAA6ytNVM4gUAWMlj6WSppWEDAGAnKl4AgJ1oNQMA4Bxbt4yk1QwAgIOoeAEAdqLVDACAg2g1AwCAQKh4AQBWsnWvZhIvAMBOtJoBAEAgVLwAADvRagYAwDnM8QIA4CTmeAEAQCBUvAAAK9FqBgDASbSaAQBAIFS8AAA70WoGAMA5XI8XAAAERMULALATrWYAABxEqxkAAARCxQsAsBIbaAAA4CRLW80kXgCAnSyteJnjBQDAQVS8AAA7WVrxkngBAHayNPHSagYAwEFUvAAAO3ntrB1JvAAAO9FqBgAAgVDxAgDsZGnFS+IFANjJ0sRLqxkAAAdR8QIA7MSqZgAAHGRpq5nECwCwk6WJ1846HQAAS1HxAgDsZGnFS+IFANjJ0sVVdkYNAIClqHgBAHai1QwAgIMsTby0mgEAcBAVLwDATpZWvCReAICVPKxqBgAAgVDxAgDsRKsZAAAHkXgBAHCQpYmXOV4AABxExQsAsJOlq5pJvAAAO9FqBgAAgVDxAgDsZGnFS+IFANjJ0sRLqxkAAAdR8QIA7MSqZgAAHESrGQAABELFCwCwk6UVL4kXAGAn5ngBAHCQpRWvnV8XAACwFBUvAMBOlla8JF4AgJ0sTby0mgEAcBAVLwDATqxqBgDAQbSaAQBAIFS8AAA7WVrxkngBAHby2Nm0tTNqAAAsRcULALCTl1YzAADOsbTVTOIFANjJ0sVVdn5dAADAUlS8AAA7sXMVAAAOotUMAAACoeIFANiJVc0AADiIVjMAAAiEihcAYCdWNQMA4CBazQAAIBAqXgCAnVjVDACAg7g6EQAADrK04rUzagAALEXFCwCwk6Wrmkm8AAA70WoGAACBUPECAOzEqmYAABxk6RwvrWYAABxExQsAsJOli6tIvAAAOzHHCwCAgyyteO2MGgAAS1HxAgDsZOmqZhIvAMBOtJoBAEAgVLwAADuxqhkAAAfRagYAAIFQ8QIA7MSqZgAAHOS1s2lrZ9QAAFiKihcAYCdazQAAOMjSVc0kXgCAnSyteO38ugAAgKWoeAEAdrJ0VTOJFwBgJ1rNAAAgECpeAICdWNUMAICDaDUDAIBAqHgBAHai1QwAgIO8tJoBAEAAVLwAADvRagYAwEGWrmom8QIA7GRpxWtn1AAAWIqKFwBgJQ+tZgAAHESrGQAABELFCwCwk6UVL4kXAGAndq4CAACBUPECAOxEqxkAAAdZejqRnV8XAACwFBUvAMBOtJoBAHCQpa1mEi8AwE6WVrx2Rg0AgKWoeAEAdrJ0Aw0SLwDATrSaAQBAIFS8AAA7saoZAAAH0WoGAACBUPECAOxEqxkAAAfRagYAAIFQ8QIA7OS1s3Yk8QIArORhjhcAAAcxxwsAAAKh4gUA2IlWMwAADqLVDAAAAqHiBQDYiVYzAAAOsvQ8XjujBgDAUlS8AAA70WoGAMBBrGoGAACBUPECAOxEqxkAACeReAEAcI6lFS9zvAAAOIiKFwBgJ0srXhIvAMBSdiZeWs0AADiIihcAYCdazQAAOMjOvEurGQAAJ1HxAgAsZWfJS+IFANjJ0jleWs0AADiIihcAYCdLK14SLwDAUiReAACcY2nFyxwvAAAOouIFAFjKzoqXxAsAsBOtZgAAEAgVLwDATpZWvCReAICl7Ey8tJoBAHAQFS8AwEoeWs0AADjI0sRLqxkAAAdR8QIALGVnxUviBQDYydJWM4kXAGAnSxMvc7wAADiIihcAYCk7K14SLwDATrSaAQBAIFS8AAA72VnwkngBALayM/PSagYAwEFUvAAAO1m6uIrECwCwk6WJl1YzAAAOouIFAFjKzoqXxAsAsBOtZgAAHOTxXJvbf+DNN99U2bJlFRYWplq1aunrr7/O9WNJvAAAXIWpU6fq2Wef1SuvvKJ169apfv36atq0qXbt2pWrx3uMMSZXR54+9kfiBADcSPIXuv6vcerotXmeiKirOvyOO+5QzZo19dZbb/nGqlSpogceeECDBw8O+HgqXgCAnVxoNaenp2vNmjW65557/Mbvueceffvtt7l6DhZXAQBuaOfOndO5c+f8xkJDQxUaGprt2EOHDikzM1PFixf3Gy9evLj279+fuxc0Ljh79qxJSUkxZ8+edePlA8rL8eXl2Iwhvj8iL8dmDPH9EXk5NmPyfnzXW0pKipHkd0tJScnx2F9++cVIMt9++63f+KBBg0ylSpVy9Xq5n+O9ho4fP65ChQrp2LFjKliwoNMvH1Beji8vxyYR3x+Rl2OTiO+PyMuxSXk/vuvtaire9PR05c+fX9OmTVPLli19488884zWr1+vpUuXBnw95ngBADe00NBQFSxY0O+WU9KVpJCQENWqVUvz58/3G58/f74SExNz9XrM8QIAcBV69Oih9u3bq3bt2qpbt67effdd7dq1S0888USuHk/iBQDgKrRq1UqHDx/WwIEDtW/fPlWtWlWff/65ypQpk6vHu5J4Q0NDlZKSctlS3m15Ob68HJtEfH9EXo5NIr4/Ii/HJuX9+PKirl27qmvXrv/RY11ZXAUAwI2KxVUAADiIxAsAgINIvAAAOIjECwCAg0i8eVxmZqaWLl2q3377ze1QgDxlwYIFl73vnXfecTCSnHXq1ElfffWV22FcVoMGDTRgwIBs47/99psaNGjgQkQ3DscSb4MGDXT06NFs48ePH3f9L3ngwIE6ffp0tvEzZ85o4MCBLkT0b/ny5VOTJk1y/Ozyiri4OA0cODDX16J02tGjRzVv3jx98MEHmjRpkt8tL9i2bZv69OmjNm3a6Ndff5Ukffnll/rxxx9djixva9asmXr27Kn09HTf2MGDB9W8eXP17t3bxcguOHHihO655x5VrFhRr732mn755Re3Q/KzZMkSjRkzRg888IBOnTrlG09PT8/Vtof4A/7IxtJXw+PxmAMHDmQbP3DggAkKCnIqjBx5vd4cYzt06JDxer0uROSvdu3aZsGCBW6HcVmjR482NWvWNPny5TONGjUyU6ZMyTObrX/66aemQIECxuv1mkKFCpmoqCjfrXDhwm6HZ5YsWWLCw8NNo0aNTEhIiNm2bZsxxpjXX3/dPPTQQy5Hd8GkSZNMYmKiKVGihNmxY4cxxpg33njDzJw509W4li9fbipWrGji4+PNxo0bzezZs02xYsVMUlKS2bVrl6uxXXTo0CEzcuRIk5CQYIKCgsy9995rpk2bZtLT090OzXg8HrN+/Xpzxx13mKpVq5rt27cbY4zZv39/nvi992d23RPvhg0bzIYNG4zH4zGLFy/2/bxhwwazdu1a89prr5kyZcpc7zCuyOPxmF9//TXb+MKFC01MTIwLEfmbO3euSUhIMJ999pnZu3evOXbsmN8tr1i/fr15+umnTdGiRU3hwoVNt27dzJo1a1yNqWLFiuaZZ54xp06dcjWOy6lTp44ZPny4McaYyMhIX+JduXKlKVmypJuhGWOMefPNN01MTIwZNGiQCQ8P98U3YcIEk5SU5HJ0xpw8edK0a9fOhIaGmuDgYPP666+brKwst8PK0dq1a0337t1NWFiYiYmJMc8++6zZunWra/FcLIbOnj1r2rZta2JiYszixYtJvA647onX4/EYr9drvF6v8Xg82W758+c348aNu95h5Ohi1eP1en1/vngrWLCg8Xq9pmvXrq7EdqlLP6+Ln+XFzzMv/gdJT083I0eONKGhocbr9Zr4+Hgzbtw4V34h5s+f35cs8qKIiAiTlpZmjPFPvNu3bzehoaFuhmaMMaZKlSpmxowZxhj/+H744QcTHR3tYmQXrFmzxlSqVMmUL1/ehIeHm86dO5uTJ0+6HVY2e/fuNampqebmm282ERERpkOHDqZx48YmKCjIjBgxwpWYft/pe/XVV01oaKjp169fnvy98mdy3beM3L59u4wxKleunFauXKmiRYv67gsJCVGxYsWUL1++6x1GjkaOHCljjLp06aIBAwaoUKFCfrHFxcWpbt26rsR2qcWLF7sdQq5kZGRoxowZmjBhgubPn686deooOTlZe/fu1SuvvKIFCxboo48+cjSmJk2aaPXq1SpXrpyjr5tbUVFR2rdvn8qWLes3vm7dOpUqVcqlqP5t+/btqlGjRrbx0NBQv3lBN6SmpiolJUWPPfaYhg4dqm3btqldu3aKj4/XBx984Pr/3YyMDH366aeaMGGC5s2bp/j4eD333HP629/+pgIFCkiSPv74Yz355JN67rnnHI/P/G7Twj59+qhKlSrq2LGj47HcaK574r24aXRWVtb1fqmrdvEfWNmyZZWYmKjg4GCXI8rZXXfd5XYIV7R27VpNmDBBU6ZMUb58+dS+fXu98cYbqly5su+Ye+65R3feeacj8Xz66ae+Pzdr1kwvvPCCNm3apGrVqmX7O77//vsdiely2rZtq169emnatGnyeDzKysrSsmXL9Pzzz6tDhw6uxiZd+L+xfv36bJu/f/HFF7rllltciuqCUaNGaebMmWratKkk6dZbb9XKlSv18ssvKykpKdv1VZ1WokQJZWVlqU2bNlq5cqUSEhKyHdOkSRNFRUU5Hpt04UvVpYWQJD300EOqXLmyVq9e7UpMNwrH92retGmTdu3a5bcSUXL3F2Cg1bixsbEORXJ5R48e1bhx47R582Z5PB7dcsst6tKli1+V7pZ8+fKpcePGSk5O1gMPPJDjF5hTp06pe/fumjBhwnWPx+vN3WJ9j8ejzMzM6xzNlWVkZKhTp076+OOPZYxRUFCQMjMz1bZtW73//vuudYMumjBhgvr27avhw4crOTlZY8eO1bZt2zR48GCNHTtWrVu3di22Q4cOKSYmJsf7li5d6voX1smTJ+uvf/2rwsLCXI0DeY9jiTctLU0tW7bUDz/8II/H42tzeDweSXL1F6DX6/XFkRO3fzmvXr1aTZo0UXh4uG6//XYZY7R69WqdOXNG8+bNU82aNV2Nb+fOnbm+HBZytm3bNq1bt05ZWVmqUaOGKlas6HZIPu+9954GDRqk3bt3S5JKlSql/v37Kzk52eXIADs5lnibN2+ufPny6b333vPN9x4+fFg9e/bUsGHDVL9+fSfCyNGGDRv8fs7IyNC6des0YsQI/f3vf9eDDz7oUmQX1K9fXxUqVNB7772noKALswPnz5/Xo48+qrS0NNdP0i9XrpxWrVql6Ohov/GjR4+qZs2aSktLcykyadKkSWrVqlW2y52lp6fr448/zhPtXFscOnRIWVlZKlasmNuhAFZzLPHGxMRo0aJFio+PV6FChbRy5UpVqlRJixYtUs+ePbVu3Tonwrgqc+bM0dChQ7VkyRJX4wgPD9e6dev85kylC2372rVr57j5h5O8Xq/279+f7RfygQMHFBsb6+pcW758+bRv375ssR0+fFjFihVzpZvRo0ePXB87YsSI6xhJYNu3b9f58+ezVeA//fSTgoODFRcX505ggMWu++KqizIzMxUZGSnpQhLeu3evKlWqpDJlymjLli1OhXFVbr75Zq1atcrtMFSwYEHt2rUrW+LdvXu3b3WkGy5dxDR37ly/+ebMzEwtXLjQ9V/MxpgcpxH27Nnj2vx4br9kXmn6wymdOnVSly5dsiXeFStWaOzYsa5/KQVs5FjirVq1qr7//nuVK1dOd9xxh4YMGaKQkBC9++67rp/qcfz4cb+fjTHat2+f+vfvnyfm2lq1aqXk5GQNGzZMiYmJ8ng8+uabb/TCCy+oTZs2rsX1wAMPSLqQIH5/CsLFamj48OEuRCbVqFFDHo9HHo9HDRs29LXopQtfCrZv3657773XldhsOT1MuvAloV69etnG69Spo+7du7sQEWA/xxJvnz59fOf9DRo0SPfdd5/q16+v6OhoTZ061akwchQVFZWtujDGqHTp0poyZYpLUf3bsGHD5PF41KFDB50/f17ShcT25JNPKjU11bW4Lp4iVrZsWa1ateqyK0zdcPFLwfr169WkSRNft0X69znaDz30kEvR5Wz37t3yeDy66aab3A7Fx+Px6MSJE9nGjx075vqiQ8BWjp9OdKkjR46ocOHCrrfUfr8huNfrVdGiRVWhQgW/Ssltp0+f1rZt22SMUYUKFZQ/f363Q8rzJk6cqFatWuXZUzrOnz+vAQMGaPTo0Tp58qQkKTIyUk899ZRSUlJcP7f8vvvuU/78+X3naEsXOgatWrXSqVOn9MUXX7gaH2AjRxLv+fPnFRYWpvXr16tq1arX++Wu2uDBg1W8eHF16dLFb3z8+PE6ePCgevXq5VJkedfo0aP12GOPKSwsTKNHj77isU8//bRDUV3e6tWrfedAV6lSRbVq1XI7JEnSE088oRkzZmjgwIG+nZa+++479e/fXy1atNDbb7/tanybNm3SnXfeqaioKN+ZB19//bWOHz+uRYsW5cn/z0Be51jFW758eX3yySeqXr26Ey93VeLi4vTRRx8pMTHRb3zFihVq3bq1tm/f7nhMV3MK0yeffHIdI8lZ2bJltXr1akVHRysuLu6yXQuPx+Pq6US//PKLWrdurWXLlvl2CDp69KgSExM1ZcoUlS5d2rXYJKlQoUL6+OOPfbsvXfTFF1+odevWOnbsmEuR/dvevXs1ZswYbdiwQeHh4YqPj1f37t1VpEgRt0MDrOToHG/v3r31wQcf5Ln/sPv371eJEiWyjRctWlT79u1zISLliR2pruTSLyM7duxwL5AAOnfurIyMDG3evFmVKlWSJG3ZskVdunRRcnKy5s2b52p8YWFhOa78jouLU0hIiPMB5aBkyZJ67bXX3A4D+NNwrOKtUaOGfv75Z2VkZKhMmTKKiIjwu3/t2rVOhJGjihUrKiUlRe3atfMbnzx5slJSUlyt2PK6jIwMVapUSbNnz3Z9796chIeH69tvv8220f/atWtVr149nTlzxqXILhg4cKD+9a9/acKECb5NPs6dO6fk5GTfv0unff/996pataq8Xq++//77Kx4bHx/vUFTAn4djFe/FVaZ50aOPPqpnn31WGRkZatCggSRp4cKFevHFF9WzZ0+Xo/u3gwcPasuWLfJ4PLr55puzbXDuhuDgYJ07d871BXKXExsbq4yMjGzj58+fd+3qP7+fRliwYIFuuukm3zTMhg0blJ6eroYNG7oRnhISEnwboiQkJPht8XqpvLDXNWAjV1c15xXGGL300ksaPXq07+INYWFh6tWrl/r16+dydBcuMPDUU09p0qRJvlN48uXLpw4dOuh///d/XV/dnJqaqn/9618aO3ZsnloFLkmzZs3Sa6+9pn/84x+qVauWPB6PVq9eraeeekq9evVy5Qth586dc32sExeV+L2dO3cqNjZWHo9HO3fuvOKx7NENXD0S7yVOnjypzZs3Kzw8XBUrVsy2v69bHn/8cS1YsEBjxozxbWbwzTff6Omnn1bjxo311ltvuRpfy5YttXDhQkVGRqpatWrZphHcWPx1UeHChXX69GmdP3/eb5/roKCgbHEeOXLEjRDzrIyMDD322GPq27ev65vcAH8mjiXezMxMvfHGG/q///u/HC8LyC+9y4uJidH06dOVlJTkN7548WI98sgjOnjwoDuB/X+BKjg3qraLJk6cmOtjuQB4dlFRUVq7di2JF7iGHOsLDhgwQGPHjlWPHj3Ut29fvfLKK9qxY4dmzpyZJ9q5ednp06dVvHjxbOPFihVz/QIJkruJNRAbkun06dMv+4XUzUWH0oVuxsyZM6/qwg4Arix3Vwy/Bj788EO99957ev755xUUFKQ2bdpo7Nix6tevn5YvX+5UGFaqW7euUlJSdPbsWd/YmTNnNGDAAN+mC7i8bdu2qU+fPmrTpo1+/fVXSdKXX36pH3/80eXILmxE0rlzZxUrVkzr1q3T7bffrujoaKWlpWU7t9cNFSpU0KuvvqqHH35YgwcP1ujRo/1uAK6eY63miIgIbd68WbGxsSpRooTmzJnju1ZrjRo18sRGAXnVDz/8oKZNm+rs2bOqXr26PB6P1q9fr9DQUM2bN0+33nqr2yHm2apt6dKlatq0qerVq6evvvpKmzdvVrly5TRkyBCtXLlS06dPdy02SapcubJSUlLUpk0bFShQQBs2bFC5cuXUr18/HTlyRGPGjHE1vrJly172Prc3RwFs5VjFe9NNN/k2o6hQoYJv44JVq1blmUVMeVW1atX0008/afDgwUpISFB8fLxSU1P1888/54mkm5ertpdeekmDBg3S/Pnz/TakuPvuu/Xdd9+5GNkFu3bt8u2YFh4e7rsgQfv27fPEBTq2b9/uu6WlpSktLc3vZwD/AeOQXr16mb///e/GGGOmTZtmgoKCTIUKFUxISIjp1auXU2FY6bXXXjPjxo3LNj5u3DiTmprqQkT+KlWqZD766CNjjDGRkZFm27Ztxhhj+vbta7p16+ZmaCYiIsKkpaUZY/xj2759uwkNDXUzNGOMMWXLljVr1qwxxhhTu3Zt8/bbbxtjjJk7d64pXLiwm6H5jB071tx6660mJCTEhISEmFtvvdW89957bocFWMuxxPt7y5cvN8OHDzezZs1yKwRrlClTxixbtizb+PLly01cXJwLEfkLDw83O3bsMMYYU7RoUbN+/XpjjDFbt241RYoUcTM0U6pUKd9nd2ni/eSTT0y5cuXcDM0YY0xycrLp37+/McaYt956y4SHh5tGjRqZqKgo06VLF5ejM6ZPnz4mIiLCvPTSS2bWrFlm1qxZ5qWXXjKRkZHmlVdecTs8wEqOJd68XrXlZaGhob6q7VLbtm2jagvghRdeMH/5y1/Mvn37TIECBcxPP/1kvvnmG1OuXDlfwnNTWlqaOXfunO/nqVOnmqeeesqMGjXKbN261cXILoiOjvZ1My710UcfmejoaBciAuznWOLN61VbXlahQgUzefLkbOOTJk0yZcuWdSEif3m5aktPTzdt27Y1Xq/XeDweExwcbDwej2nXrp05f/68q7EZY4zX6zUHDhzINn7o0CHj9XpdiMhfVFRUjl8AtmzZYgoVKuR8QMCfgGPn8ebFKwDZIq/vJf3uu+/6trJ84oknVKRIEX3zzTdq3ry5nnjiCVdjCw4O1ocffqhXX31Va9euVVZWlmrUqKGKFSu6GtdF5jInFZw8eVJhYWEOR5Ndu3bt9NZbb2nEiBF+4++++67+9re/uRQVYDfHEm/p0qW1bNmybKcnLFu2TCVLlnQqDCu9+OKLOnLkiLp27ZptL+nevXu7HJ3k9Xrl9f57gfwjjzyiRx55xLV4Am32cOl5479PKE65GKPH41G/fv389tvOzMzUihUrlJCQ4Epsvzdu3DjNmzdPderUkXTh89u9e7c6dOjg91m79VkCtnEs8eb1qi0v83g8ev3119W3b988s5d0oMvFXcrpS8etW7fO7+c1a9YoMzPTdz3erVu3Kl++fKpVq5ajcV3qYozGGP3www9+pzqFhISoevXqev75590Kz2fjxo2qWbOmpAsbkUgXulRFixbVxo0bfcfl1atTAXmRYxtomDx+BSBcHa/Xe9nLxV3K7UvHjRgxQkuWLNHEiRNVuHBhSdJvv/2mzp07q379+q5/6evcubNGjRqlggULuhoHAOc4fnWivHoFIFydQJeLu5Sbl44rVapUjrt7bdy4Uffcc4/27t3rUmQAblSOXzw1MjJSt912m9Mvi2vs0mQ6ePBgFS9eXF26dPE7Zvz48Tp48KB69erldHg+x48f14EDB7Il3l9//dW3SxQAOMmxLSPx5/XOO++ocuXK2cZvvfVWvf322y5E9G8tW7ZU586dNX36dO3Zs0d79uzR9OnTlZycrAcffNDV2ADcmBxvNePPJywsTJs3b862Yj0tLU233HKL31WVnHb69Gk9//zzGj9+vDIyMiRJQUFBSk5O1tChQxUREeFabABuTI63mvHnk5dPFcufP7/efPNNDR06VNu2bZMxRhUqVCDhAnANiRd/mA2nikVERDh+WhMA5IRWM/4wThUDgNwj8eKa4VQxAAiMxAsAgIM4nQgAAAeReAEAcBCJFwAAB5F4AQBwEIkXAAAHkXgBAHAQiRcAAAeReAEAcND/Az+q7vWfSu9PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# no missing values\n",
    "fig, ax = plt.subplots(1,1)\n",
    "sns.heatmap(diamonds.isna(), ax=ax,\n",
    "           vmin=0, vmax=1, cmap=\"Reds\",\n",
    "           cbar_kws={\"ticks\":[0,1]})\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Show Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dummy variables\n",
    "\n",
    "Since in the diamond dataset we have three categorical input features, we need to convert them into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_I1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36798</th>\n",
       "      <td>0.34</td>\n",
       "      <td>62.8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>956</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.79</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21810</th>\n",
       "      <td>1.04</td>\n",
       "      <td>62.8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9882</td>\n",
       "      <td>6.45</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23454</th>\n",
       "      <td>1.91</td>\n",
       "      <td>60.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11447</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.09</td>\n",
       "      <td>4.89</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39231</th>\n",
       "      <td>0.38</td>\n",
       "      <td>61.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1067</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.89</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>0.84</td>\n",
       "      <td>63.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3145</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table  price     x     y     z  cut_Ideal  cut_Premium  \\\n",
       "36798   0.34   62.8   58.0    956  4.45  4.43  2.79      False         True   \n",
       "21810   1.04   62.8   58.0   9882  6.45  6.42  4.04      False         True   \n",
       "23454   1.91   60.7   56.0  11447  8.01  8.09  4.89       True        False   \n",
       "39231   0.38   61.6   57.0   1067  4.65  4.73  2.89       True        False   \n",
       "2219    0.84   63.6   57.0   3145  5.95  6.00  3.80      False        False   \n",
       "\n",
       "       cut_Very Good  ...  color_I  color_J  clarity_IF  clarity_VVS1  \\\n",
       "36798          False  ...    False    False       False         False   \n",
       "21810          False  ...    False    False       False         False   \n",
       "23454          False  ...    False     True       False         False   \n",
       "39231          False  ...    False    False       False          True   \n",
       "2219            True  ...    False    False       False         False   \n",
       "\n",
       "       clarity_VVS2  clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  \\\n",
       "36798         False        False         True        False        False   \n",
       "21810          True        False        False        False        False   \n",
       "23454         False        False        False         True        False   \n",
       "39231         False        False        False        False        False   \n",
       "2219          False        False        False        False         True   \n",
       "\n",
       "       clarity_I1  \n",
       "36798       False  \n",
       "21810       False  \n",
       "23454       False  \n",
       "39231       False  \n",
       "2219        False  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate dummies for categorical features\n",
    "diamonds = pd.get_dummies(diamonds)\n",
    "diamonds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining inputs and output\n",
    "X = diamonds.drop(\"price\", axis=1)\n",
    "y = diamonds[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing training data\n",
    "st_scaler = StandardScaler()\n",
    "st_scaler.fit(X_train)\n",
    "X_train_scaled = st_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ANN\n",
    "model = Sequential(\n",
    "    [Dense(36, activation=\"relu\", input_shape=[X_train.shape[1]]),\n",
    "    Dense(36, activation=\"relu\"),\n",
    "     Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the ANN\n",
    "model.compile(loss='mse',\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"mae\", \"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">972</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,332</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                  │             \u001b[38;5;34m972\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                  │           \u001b[38;5;34m1,332\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m37\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,341</span> (9.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,341\u001b[0m (9.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,341</span> (9.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,341\u001b[0m (9.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - loss: 17152134.0000 - mae: 2662.4119 - mse: 17152134.0000 - val_loss: 2678416.7500 - val_mae: 1107.3782 - val_mse: 2678416.7500\n",
      "Epoch 2/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 1746839.7500 - mae: 774.2750 - mse: 1746839.7500 - val_loss: 940222.0625 - val_mae: 611.7204 - val_mse: 940222.0625\n",
      "Epoch 3/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - loss: 1148429.8750 - mae: 604.5130 - mse: 1148429.8750 - val_loss: 761777.5000 - val_mae: 576.1616 - val_mse: 761777.5000\n",
      "Epoch 4/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1056158.6250 - mae: 581.9449 - mse: 1056158.6250 - val_loss: 717065.8125 - val_mae: 557.5765 - val_mse: 717065.8125\n",
      "Epoch 5/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 1001511.6875 - mae: 560.0383 - mse: 1001511.6875 - val_loss: 688537.8750 - val_mae: 531.5144 - val_mse: 688537.8750\n",
      "Epoch 6/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 953080.5625 - mae: 535.6542 - mse: 953080.5625 - val_loss: 653471.3125 - val_mae: 513.1050 - val_mse: 653471.3125\n",
      "Epoch 7/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 908922.3750 - mae: 516.9064 - mse: 908922.3750 - val_loss: 626933.0000 - val_mae: 497.7030 - val_mse: 626933.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - loss: 872302.5000 - mae: 499.2044 - mse: 872302.5000 - val_loss: 602032.3125 - val_mae: 478.3682 - val_mse: 602032.3125\n",
      "Epoch 9/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - loss: 838298.8125 - mae: 481.0987 - mse: 838298.8125 - val_loss: 582568.8750 - val_mae: 456.5553 - val_mse: 582568.8750\n",
      "Epoch 10/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - loss: 798517.8125 - mae: 462.7580 - mse: 798517.8125 - val_loss: 570242.5625 - val_mae: 440.9474 - val_mse: 570242.5625\n",
      "Epoch 11/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 767083.1250 - mae: 447.7675 - mse: 767083.1250 - val_loss: 537286.4375 - val_mae: 430.5726 - val_mse: 537286.4375\n",
      "Epoch 12/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 741755.8125 - mae: 435.8823 - mse: 741755.8125 - val_loss: 520241.9375 - val_mae: 416.2569 - val_mse: 520241.9375\n",
      "Epoch 13/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 716301.1250 - mae: 423.9326 - mse: 716301.1250 - val_loss: 505044.0625 - val_mae: 406.7989 - val_mse: 505044.0625\n",
      "Epoch 14/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 692104.9375 - mae: 415.0442 - mse: 692104.9375 - val_loss: 491014.3125 - val_mae: 397.3404 - val_mse: 491014.3125\n",
      "Epoch 15/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 669091.1250 - mae: 406.3934 - mse: 669091.1250 - val_loss: 483192.0312 - val_mae: 392.8683 - val_mse: 483192.0312\n",
      "Epoch 16/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 648893.2500 - mae: 399.5416 - mse: 648893.2500 - val_loss: 470861.7812 - val_mae: 384.3613 - val_mse: 470861.7812\n",
      "Epoch 17/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 633282.3750 - mae: 393.5713 - mse: 633282.3750 - val_loss: 463140.9375 - val_mae: 378.3261 - val_mse: 463140.9375\n",
      "Epoch 18/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 615953.0000 - mae: 388.2083 - mse: 615953.0000 - val_loss: 472037.4688 - val_mae: 380.6950 - val_mse: 472037.4688\n",
      "Epoch 19/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 603115.0000 - mae: 383.9641 - mse: 603115.0000 - val_loss: 473044.6875 - val_mae: 377.5116 - val_mse: 473044.6875\n",
      "Epoch 20/20\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 587561.6875 - mae: 380.9825 - mse: 587561.6875 - val_loss: 443454.7188 - val_mae: 367.2001 - val_mse: 443454.7188\n"
     ]
    }
   ],
   "source": [
    "# train the ANN\n",
    "epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train.values,\n",
    "                   epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9296.257  ],\n",
       "       [  750.63385],\n",
       "       [10391.029  ],\n",
       "       [ 2784.4197 ],\n",
       "       [ 3318.8655 ],\n",
       "       [  832.1019 ],\n",
       "       [ 6911.986  ],\n",
       "       [ 4232.4907 ],\n",
       "       [ 7667.2285 ],\n",
       "       [ 2586.6917 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate predictions\n",
    "model.predict(X_train_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.715213e+07</td>\n",
       "      <td>2662.411865</td>\n",
       "      <td>1.715213e+07</td>\n",
       "      <td>2.678417e+06</td>\n",
       "      <td>1107.378174</td>\n",
       "      <td>2.678417e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.746840e+06</td>\n",
       "      <td>774.275024</td>\n",
       "      <td>1.746840e+06</td>\n",
       "      <td>9.402221e+05</td>\n",
       "      <td>611.720398</td>\n",
       "      <td>9.402221e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.148430e+06</td>\n",
       "      <td>604.513000</td>\n",
       "      <td>1.148430e+06</td>\n",
       "      <td>7.617775e+05</td>\n",
       "      <td>576.161621</td>\n",
       "      <td>7.617775e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.056159e+06</td>\n",
       "      <td>581.944885</td>\n",
       "      <td>1.056159e+06</td>\n",
       "      <td>7.170658e+05</td>\n",
       "      <td>557.576538</td>\n",
       "      <td>7.170658e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.001512e+06</td>\n",
       "      <td>560.038330</td>\n",
       "      <td>1.001512e+06</td>\n",
       "      <td>6.885379e+05</td>\n",
       "      <td>531.514404</td>\n",
       "      <td>6.885379e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.530806e+05</td>\n",
       "      <td>535.654236</td>\n",
       "      <td>9.530806e+05</td>\n",
       "      <td>6.534713e+05</td>\n",
       "      <td>513.104980</td>\n",
       "      <td>6.534713e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.089224e+05</td>\n",
       "      <td>516.906372</td>\n",
       "      <td>9.089224e+05</td>\n",
       "      <td>6.269330e+05</td>\n",
       "      <td>497.702972</td>\n",
       "      <td>6.269330e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.723025e+05</td>\n",
       "      <td>499.204376</td>\n",
       "      <td>8.723025e+05</td>\n",
       "      <td>6.020323e+05</td>\n",
       "      <td>478.368225</td>\n",
       "      <td>6.020323e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.382988e+05</td>\n",
       "      <td>481.098724</td>\n",
       "      <td>8.382988e+05</td>\n",
       "      <td>5.825689e+05</td>\n",
       "      <td>456.555298</td>\n",
       "      <td>5.825689e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.985178e+05</td>\n",
       "      <td>462.757965</td>\n",
       "      <td>7.985178e+05</td>\n",
       "      <td>5.702426e+05</td>\n",
       "      <td>440.947388</td>\n",
       "      <td>5.702426e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.670831e+05</td>\n",
       "      <td>447.767548</td>\n",
       "      <td>7.670831e+05</td>\n",
       "      <td>5.372864e+05</td>\n",
       "      <td>430.572601</td>\n",
       "      <td>5.372864e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.417558e+05</td>\n",
       "      <td>435.882294</td>\n",
       "      <td>7.417558e+05</td>\n",
       "      <td>5.202419e+05</td>\n",
       "      <td>416.256927</td>\n",
       "      <td>5.202419e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.163011e+05</td>\n",
       "      <td>423.932587</td>\n",
       "      <td>7.163011e+05</td>\n",
       "      <td>5.050441e+05</td>\n",
       "      <td>406.798920</td>\n",
       "      <td>5.050441e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.921049e+05</td>\n",
       "      <td>415.044159</td>\n",
       "      <td>6.921049e+05</td>\n",
       "      <td>4.910143e+05</td>\n",
       "      <td>397.340393</td>\n",
       "      <td>4.910143e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.690911e+05</td>\n",
       "      <td>406.393433</td>\n",
       "      <td>6.690911e+05</td>\n",
       "      <td>4.831920e+05</td>\n",
       "      <td>392.868347</td>\n",
       "      <td>4.831920e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.488932e+05</td>\n",
       "      <td>399.541595</td>\n",
       "      <td>6.488932e+05</td>\n",
       "      <td>4.708618e+05</td>\n",
       "      <td>384.361328</td>\n",
       "      <td>4.708618e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.332824e+05</td>\n",
       "      <td>393.571289</td>\n",
       "      <td>6.332824e+05</td>\n",
       "      <td>4.631409e+05</td>\n",
       "      <td>378.326141</td>\n",
       "      <td>4.631409e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.159530e+05</td>\n",
       "      <td>388.208313</td>\n",
       "      <td>6.159530e+05</td>\n",
       "      <td>4.720375e+05</td>\n",
       "      <td>380.695007</td>\n",
       "      <td>4.720375e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.031150e+05</td>\n",
       "      <td>383.964111</td>\n",
       "      <td>6.031150e+05</td>\n",
       "      <td>4.730447e+05</td>\n",
       "      <td>377.511597</td>\n",
       "      <td>4.730447e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.875617e+05</td>\n",
       "      <td>380.982544</td>\n",
       "      <td>5.875617e+05</td>\n",
       "      <td>4.434547e+05</td>\n",
       "      <td>367.200104</td>\n",
       "      <td>4.434547e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss          mae           mse      val_loss      val_mae  \\\n",
       "0   1.715213e+07  2662.411865  1.715213e+07  2.678417e+06  1107.378174   \n",
       "1   1.746840e+06   774.275024  1.746840e+06  9.402221e+05   611.720398   \n",
       "2   1.148430e+06   604.513000  1.148430e+06  7.617775e+05   576.161621   \n",
       "3   1.056159e+06   581.944885  1.056159e+06  7.170658e+05   557.576538   \n",
       "4   1.001512e+06   560.038330  1.001512e+06  6.885379e+05   531.514404   \n",
       "5   9.530806e+05   535.654236  9.530806e+05  6.534713e+05   513.104980   \n",
       "6   9.089224e+05   516.906372  9.089224e+05  6.269330e+05   497.702972   \n",
       "7   8.723025e+05   499.204376  8.723025e+05  6.020323e+05   478.368225   \n",
       "8   8.382988e+05   481.098724  8.382988e+05  5.825689e+05   456.555298   \n",
       "9   7.985178e+05   462.757965  7.985178e+05  5.702426e+05   440.947388   \n",
       "10  7.670831e+05   447.767548  7.670831e+05  5.372864e+05   430.572601   \n",
       "11  7.417558e+05   435.882294  7.417558e+05  5.202419e+05   416.256927   \n",
       "12  7.163011e+05   423.932587  7.163011e+05  5.050441e+05   406.798920   \n",
       "13  6.921049e+05   415.044159  6.921049e+05  4.910143e+05   397.340393   \n",
       "14  6.690911e+05   406.393433  6.690911e+05  4.831920e+05   392.868347   \n",
       "15  6.488932e+05   399.541595  6.488932e+05  4.708618e+05   384.361328   \n",
       "16  6.332824e+05   393.571289  6.332824e+05  4.631409e+05   378.326141   \n",
       "17  6.159530e+05   388.208313  6.159530e+05  4.720375e+05   380.695007   \n",
       "18  6.031150e+05   383.964111  6.031150e+05  4.730447e+05   377.511597   \n",
       "19  5.875617e+05   380.982544  5.875617e+05  4.434547e+05   367.200104   \n",
       "\n",
       "         val_mse  \n",
       "0   2.678417e+06  \n",
       "1   9.402221e+05  \n",
       "2   7.617775e+05  \n",
       "3   7.170658e+05  \n",
       "4   6.885379e+05  \n",
       "5   6.534713e+05  \n",
       "6   6.269330e+05  \n",
       "7   6.020323e+05  \n",
       "8   5.825689e+05  \n",
       "9   5.702426e+05  \n",
       "10  5.372864e+05  \n",
       "11  5.202419e+05  \n",
       "12  5.050441e+05  \n",
       "13  4.910143e+05  \n",
       "14  4.831920e+05  \n",
       "15  4.708618e+05  \n",
       "16  4.631409e+05  \n",
       "17  4.720375e+05  \n",
       "18  4.730447e+05  \n",
       "19  4.434547e+05  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect metrics by epoch\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4141.513491</td>\n",
       "      <td>1636.586921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1321.680654</td>\n",
       "      <td>969.650485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1071.648205</td>\n",
       "      <td>872.798659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1027.695784</td>\n",
       "      <td>846.797386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.755558</td>\n",
       "      <td>829.781824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>976.258451</td>\n",
       "      <td>808.375725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>953.374205</td>\n",
       "      <td>791.791008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>933.971359</td>\n",
       "      <td>775.907412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>915.586595</td>\n",
       "      <td>763.261996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>893.598239</td>\n",
       "      <td>755.144067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>875.832818</td>\n",
       "      <td>732.998252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>861.252467</td>\n",
       "      <td>721.277989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846.345748</td>\n",
       "      <td>710.664522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>831.928445</td>\n",
       "      <td>700.724134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>817.979905</td>\n",
       "      <td>695.120156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>805.539105</td>\n",
       "      <td>686.193691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>795.790409</td>\n",
       "      <td>680.544589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>784.826732</td>\n",
       "      <td>687.049830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>776.604790</td>\n",
       "      <td>687.782442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>766.525725</td>\n",
       "      <td>665.923959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rmse     val_rmse\n",
       "0   4141.513491  1636.586921\n",
       "1   1321.680654   969.650485\n",
       "2   1071.648205   872.798659\n",
       "3   1027.695784   846.797386\n",
       "4   1000.755558   829.781824\n",
       "5    976.258451   808.375725\n",
       "6    953.374205   791.791008\n",
       "7    933.971359   775.907412\n",
       "8    915.586595   763.261996\n",
       "9    893.598239   755.144067\n",
       "10   875.832818   732.998252\n",
       "11   861.252467   721.277989\n",
       "12   846.345748   710.664522\n",
       "13   831.928445   700.724134\n",
       "14   817.979905   695.120156\n",
       "15   805.539105   686.193691\n",
       "16   795.790409   680.544589\n",
       "17   784.826732   687.049830\n",
       "18   776.604790   687.782442\n",
       "19   766.525725   665.923959"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate RMSE for better interpretability\n",
    "root_metrics_df = history_df[[\"mse\", \"val_mse\"]].apply(np.sqrt)\n",
    "root_metrics_df.rename({\"mse\":\"rmse\", \"val_mse\":\"val_rmse\"}, axis=1, inplace=True)\n",
    "root_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.Figure(figsize=(14,6), dpi=100)\n",
    "\n",
    "plt.plot(root_metrics_df[\"rmse\"], label = 'Training error')\n",
    "plt.plot(root_metrics_df[\"val_rmse\"], label = 'Validation error')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "# plt.xlim([0, epochs])\n",
    "plt.xticks(range(1,20))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m506/506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# generate predictions on test set\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  682.7322407064134\n",
      "MAE:  370.5621032714844\n"
     ]
    }
   ],
   "source": [
    "# report performance on test set\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
