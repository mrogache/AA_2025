{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc0ec06",
   "metadata": {},
   "source": [
    "# `AA Workshop 9` â€” Coding Challenge\n",
    "\n",
    "Complete the tasks below to practice implementing classification modeling from `W9_Trees_Ensembles.ipynb`.\n",
    "\n",
    "Guidelines:\n",
    "- Work in order. Run each cell after editing with Shift+Enter.\n",
    "- Keep answers short; focus on making things work.\n",
    "- If a step fails, read the error and fix it.\n",
    "\n",
    "By the end you will have exercised:\n",
    "- implementing a decision tree\n",
    "- determining the optimal alpha to control overfitting\n",
    "- plotting a tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fdc70a",
   "metadata": {},
   "source": [
    "## Task 1 - Training a Generalizable Tree Classifier for Detecting Forged Banknotes\n",
    "\n",
    "You are already familiar with the dataset containing data extracted from images that were taken from genuine and forged banknote-like specimens (raw data available as `BankNote_Authentication.csv` in the `data` directory; more information [here](https://archive.ics.uci.edu/dataset/267/banknote+authentication)). Let's train a decision tree classifier, and pay particular attention to the problem of overfitting by implementing a grid search over the identified effective alphas to determine where predictive performance is maximized. Do the following:\n",
    "- load and inspect the data, then define your feature vector X (we only want to consider the features `variance` and `entropy`) and target Y (the `class`)\n",
    "- perform a train-holdout-test split\n",
    "- train a decision tree without a limit on the maximum depth, then compute the cost complexity pruning path\n",
    "- calculate and plot the training vs. holdout accuracy for each effective alpha\n",
    "- finally, plot the best performing tree and calculate the accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79340736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# load and inspect data\n",
    "data = pd.read_csv(\"../data/BankNote_Authentication.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y\n",
    "X = np.array(data[[\"variance\", \"entropy\"]])\n",
    "Y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc4bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train-holdout-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=123)\n",
    "x_train, x_hold, y_train, y_hold = train_test_split(x_train, y_train, test_size=(0.2/0.7), random_state=123)\n",
    "\n",
    "print(len(x_train), len(x_hold), len(x_test))\n",
    "\n",
    "# fit decision tree (without limit on max_depth, i.e. tree will grow fully if alpha is set to 0)\n",
    "tree_classifier = DecisionTreeClassifier(random_state=0, \n",
    "                                         criterion=\"gini\")\n",
    "\n",
    "# compute cost_complexity_pruning_path \n",
    "path = tree_classifier.cost_complexity_pruning_path(x_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa95c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train = []\n",
    "scores_hold = []\n",
    "\n",
    "# run loop\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    model.fit(x_train, y_train)    \n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, model.predict(x_train))\n",
    "    accuracy_hold = accuracy_score(y_hold, model.predict(x_hold))\n",
    "    scores_hold.append(accuracy_hold)\n",
    "    scores_train.append(accuracy_train)\n",
    "    \n",
    "# collect results in DF\n",
    "df = pd.DataFrame(columns=[\"alpha\",\"train_score\",\"holdout_score\"])\n",
    "df[\"alpha\"]=ccp_alphas\n",
    "df[\"train_score\"] = scores_train\n",
    "df[\"holdout_score\"] = scores_hold\n",
    "\n",
    "# show top five alphas\n",
    "df.sort_values(\"holdout_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e49d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df for plotting\n",
    "df = df.sort_values(\"alpha\",ascending=True)[:-1] # remove the last alpha as this corresponds to a tree with only the root node\n",
    "\n",
    "print(\"Optimal holdout accuracy of\", round(df.iloc[df.holdout_score.idxmax()].holdout_score,2), \"at an alpha of\", round(df.iloc[df.holdout_score.idxmax()].alpha,4))\n",
    "plt.subplots(figsize=(8,6))\n",
    "plt.plot(df[\"alpha\"],df[\"train_score\"], marker='o')\n",
    "plt.plot(df[\"alpha\"],df[\"holdout_score\"], marker='o')\n",
    "plt.legend([\"train\",\"holdout\"])\n",
    "plt.xlabel(\"effective alpha\",fontsize=16)\n",
    "plt.ylabel(\"accuracy\",fontsize=16)\n",
    "plt.title(\"Accuracy for different alpha\",fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd065c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test accuracy\n",
    "model = DecisionTreeClassifier(random_state=0, ccp_alpha=df.iloc[df.holdout_score.idxmax()].alpha)\n",
    "model.fit(x_train, y_train)    \n",
    "    \n",
    "accuracy_test = accuracy_score(y_test, model.predict(x_test))\n",
    "print(\"Test Accuracy:\", round(accuracy_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(model,\n",
    "                               feature_names=['variance','entropy'],\n",
    "                              class_names = [\"genuine\",\"forged\"],out_file=None)  \n",
    "    \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
